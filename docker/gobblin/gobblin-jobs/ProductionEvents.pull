job.name=GobblinKafkaQuickStart
job.group=GobblinKafka
job.description=Gobblin quick start job for Kafka
job.lock.enabled=false

kafka.brokers=kafka:9092
kafka.deserializer.type=STRING
topic.whitelist=spark

project.avro.schema=[{"columnName":"erpData","dataType":{"values":"string","type":"map"},"waterMark":false,"primaryKey":0,"length":40,"precision":0,"scale":0,"isNullable":true,"comment":"erpData","unique":false},{"columnName":"specData","dataType":{"values":"string","type":"map"},"waterMark":false,"primaryKey":0,"length":80,"precision":0,"scale":0,"isNullable":true,"comment":"specData","unique":false},{"columnName":"prodData","dataType":{"type":"string"},"waterMark":false,"primaryKey":0,"length":60,"precision":0,"scale":0,"isNullable":true,"comment":"prodData","unique":false}]
source.class=com.project.FixedSchemaKafkaDeserializerSource

converter.classes=gobblin.converter.json.JsonStringToJsonIntermediateConverter,gobblin.converter.avro.JsonIntermediateToAvroConverter

extract.namespace=gobblin.extract.kafka

writer.file.path.type=tablename
writer.destination.type=HDFS
writer.output.format=AVRO

fs.uri=hdfs://hadoop:9000/
writer.fs.uri=hdfs://hadoop:9000/
state.store.fs.uri=hdfs://hadoop:9000/

data.publisher.type=gobblin.publisher.BaseDataPublisher
data.publisher.final.dir=hdfs://hadoop:9000/

mr.job.max.mappers=1

metrics.reporting.file.enabled=true
metrics.log.dir=${env:GOBBLIN_WORK_DIR}/metrics
metrics.reporting.file.suffix=txt

bootstrap.with.offset=earliest
